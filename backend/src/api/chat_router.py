from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse

from ..repository.models.chats import SimpleChatRequest, ChatRequest, ResumeResearchRequest
from ..services.chat_service import create_chat_service
from ..services.deep_research import create_deep_research_service
from ..utils.logger import logger

chat_router = APIRouter(prefix="/api", tags=["Chat"])


@chat_router.post("/invoke-agent")
async def invoke_agent_endpoint(request: ChatRequest):
    """
    Agent æ¨¡å¼ - æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œè‡ªåŠ¨è§„åˆ’æ‰§è¡Œ
    
    Args:
        request: åŒ…å« message, model, mcp_servers, chat_history, custom_model
        
    Returns:
        StreamingResponse: SSE æµå¼å“åº”
    """
    logger.info(f"ğŸ¤– æ”¶åˆ° Agent è¯·æ±‚ | message: {request.message[:100]}... | model: {request.model} | mcp_servers: {len(request.mcp_servers or [])} | custom_model: {bool(request.custom_model)}")
    
    # åˆ›å»ºèŠå¤©æœåŠ¡ï¼ˆä» config.yaml è¯»å–é…ç½®ï¼‰
    chat_service = create_chat_service()
    
    # å¤„ç†èŠå¤©å†å²
    chat_history = request.chat_history or []
    
    # å°† custom_model è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
    custom_model_dict = None
    if request.custom_model:
        custom_model_dict = {
            "baseUrl": request.custom_model.baseUrl,
            "apiKey": request.custom_model.apiKey,
            "modelName": request.custom_model.modelName
        }
    
    # å¤„ç†èµ„æºæ–‡ä»¶
    resource_files = None
    if request.resource_files:
        resource_files = [
            {
                "name": rf.name,
                "content": rf.content,
                "type": rf.type
            }
            for rf in request.resource_files
        ]
        logger.info(f"ğŸ“„ æ”¶åˆ° {len(resource_files)} ä¸ªèµ„æºæ–‡ä»¶")
    
    return StreamingResponse(
        chat_service.invoke(
            message=request.message,
            mcp_servers=request.mcp_servers,
            chat_history=chat_history,
            custom_model=custom_model_dict,
            resource_files=resource_files
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )


@chat_router.post("/invoke-deep-research")
async def invoke_deep_research_endpoint(request: SimpleChatRequest):
    """
    Deep Research æ¨¡å¼ - æ·±åº¦ç ”ç©¶åŠ©æ‰‹
    
    å¤šé˜¶æ®µç ”ç©¶æµç¨‹ï¼š
    1. æ¾„æ¸…ç ”ç©¶èŒƒå›´
    2. åˆ¶å®šç ”ç©¶è®¡åˆ’
    3. æ‰§è¡Œæ·±åº¦ç ”ç©¶
    4. ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
    
    Args:
        request: åŒ…å« message, model, chat_history
        
    Returns:
        StreamingResponse: SSE æµå¼å“åº”ï¼ŒåŒ…å«å®Œæ•´çš„ç ”ç©¶è¿‡ç¨‹
    """
    logger.info(f"ğŸ”¬ æ”¶åˆ° Deep Research è¯·æ±‚ | query: {request.message[:100]}... | model: {request.model}")
    
    # åˆ›å»ºç ”ç©¶æœåŠ¡ï¼ˆä» config.yaml è¯»å–é…ç½®ï¼‰
    research_service = create_deep_research_service()
    chat_history = request.chat_history or []
    
    return StreamingResponse(
        research_service.invoke(
            request.message,
            chat_history,
            skip_clarification=request.skip_clarification,
            continue_research=request.continue_research,
            thread_id=request.thread_id,
            resume=request.resume
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )


@chat_router.post("/resume-deep-research")
async def resume_deep_research_endpoint(request: ResumeResearchRequest):
    """
    æ¢å¤æš‚åœçš„æ·±åº¦ç ”ç©¶æµç¨‹
    
    ç”¨æˆ·ç¡®è®¤ TodoList åï¼Œä» LangGraph checkpoint æ¢å¤æ‰§è¡Œ
    
    Args:
        request: åŒ…å« thread_id å’Œç¡®è®¤çŠ¶æ€
        
    Returns:
        StreamingResponse: SSE æµå¼å“åº”
    """
    request = ResumeResearchRequest(**request.dict()) if not isinstance(request, ResumeResearchRequest) else request
    
    logger.info(f"ğŸ”„ æ¢å¤ç ”ç©¶ | thread_id: {request.thread_id} | confirmed: {request.confirmed}")
    
    # åˆ›å»ºç ”ç©¶æœåŠ¡ï¼ˆä» config.yaml è¯»å–é…ç½®ï¼‰
    research_service = create_deep_research_service()
    
    return StreamingResponse(
        research_service.invoke(
            query="",
            chat_history=[],
            skip_clarification=False,
            continue_research=False,
            thread_id=request.thread_id,
            resume=True,
            confirmed=request.confirmed
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )